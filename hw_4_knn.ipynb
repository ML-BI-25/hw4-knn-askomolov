{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание №4 - Метод К-ближайших соседей (K-neariest neighbors)\n",
    "\n",
    "Сегодня мы с вами реализуем наш первый алгоритм машинного обучения на Python, метод К-ближайших соседей. Мы попытаемся решить с помощью него задачи:\n",
    "- бинарной классификации (то есть, только двум классам)\n",
    "- многоклассовой классификации (то есть, нескольким классам)\n",
    "- регрессии (когда зависимая переменная - натуральное число)\n",
    "\n",
    "Так как методу необходим гиперпараметр (hyperparameter) - количество соседей, то нам нужно научиться подбирать этот параметр. Мы постараемся научиться пользовать numpy для векторизованных вычислений (очень полезно, чтобы писать красивый и эффективный код), а также посмотрим на несколько метрик, которые используются в задачах классификации и регрессии.\n",
    "\n",
    "Перед выполнением задания:\n",
    "- установите все необходимые библиотеки, запустив `pip install -r requirements.txt`\n",
    "- Если вы раньше не работали с numpy или позабыли его, то можно вспомнить здесь:  \n",
    "http://cs231n.github.io/python-numpy-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# импорт из knn.py и metrics.py\n",
    "from knn import KNNClassifier\n",
    "from metrics import binary_classification_metrics, multiclass_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = 12, 9\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "SEED = 111\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# эти строчки позволят ноутбуку видеть изменения в knn.py и metrics.py\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1. KNN на датасете Fashion-MNIST\n",
    "\n",
    "**100 баллов**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом задании вам предстоит поработать с картинками одежды, среди которых можно выделить 10 классов. Данные уже загружены за вас: в переменной X лежат 70000 картинок размером 28 на 28 пикселей, вытянутые в вектор размерностью 784 (28 * 28). Так как данных довольно много, а наш KNN будет весьма медленный, то возьмем случайно 1000 наблюдений (в реальности в зависимости от вашей реализации можно будет взять больше, но если будет не зватать ОЗУ, то берите меньше)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_openml(name=\"Fashion-MNIST\", return_X_y=True, as_frame=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_stay = np.random.choice(np.arange(X.shape[0]), replace=False, size=1000)\n",
    "X = X[idx_to_stay]\n",
    "y = y[idx_to_stay]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Перед работой с любыми данными очень важно изучить их визуально и через описательные статистики.** \n",
    "\n",
    "Давайте посмотрим на какое-нибудь изображение из наших данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# возьмем случайную картинку и сделаем reshape\n",
    "# 28, 28, 1 = H, W, C (число каналов, в данном случае 1)\n",
    "image = X[np.random.choice(np.arange(X.shape[0]))].reshape(28, 28, 1)\n",
    "plt.imshow(image)\n",
    "plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1-3. Посмотрим на все классы, сделайте небольшой EDA и разделите данные на train/test (10 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмите по одной картинке каждого класса и изобразите их (например, сделайте subplots 5 на 2). Не забудьте подписать название класса над каждой картинкой. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "YOUR CODE\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Первый шаг при работе с любым датасетом это EDA**. Всегда ничинайте работу с EDA (пусть даже и небольшого). Цель EDA - это узнать что-то новое о данных, понять их структуру, а также найти возможные подводные камни или эффективные решения при построении модели.\n",
    "\n",
    "Начнем с небольшого. Посмотрите на баланс классов, один из ключевых параметров в датасетах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "YOUR CODE\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ваши выводы из EDA:**\n",
    "\n",
    "*E.g. все классы сбалансированы или некоторые классы не сбалансированы, требуется дополнительная обработка и т.д*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделите данные на тренировочную и тестовую выборки, размеры тестовой выборки выберите сами. Здесь вам может помочь функция `train_test_split`. Совет: после разбиения всегда выводите количество объектов, попавших в каждый сплит."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "YOUR CODE\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. KNN для бинарной классификации (50 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте возьмем для задачи бинарной классификации только объекты с метками классов 0 и 1.\n",
    "\n",
    "**Вопрос. Как сделать лучше: фильтровать данные до или после разбиения? Почему?** (5 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ответ:\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "YOUR CODE\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И вот мы подготовили данные, но модели у нас пока что нет. В нескольких занятиях нашего курса вам придется самостоятельно реализовывать какие-то алгоритмы машинного обучения, а потом сравнивать их с готовыми библиотечными решениями. В остальных заданиях реализовывать алгоритмы будет не обязательно, но может быть полезно, поэтому часто это будут задания на дополнительные баллы, но главное не это, а **понимание работы алгоритма после его реализации с нуля на простом numpy**. Также это все потом можно оформить в виде репозитория ml_from_scratch и хвастаться перед друзьями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_classifier = KNNClassifier(k=1)\n",
    "knn_classifier.fit(binary_train_X, binary_train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.1 Настало время писать код! (30 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В KNN нам нужно для каждого тестового примера найти расстояния до всех точек обучающей выборки. Допустим у нас 1000 примеров в train'е и 100 в test'е, тогда в итоге мы бы хотели получить матрицу попарных расстояний (например, размерностью 100 на 1000). Это можно сделать несколькими способами, и кому-то наверняка, в голову приходит идея с двумя вложенными циклами (надеюсь, что не больше:). Так можно делать, но можно и эффективнее. \n",
    "\n",
    "**Примечание:** Вообще, в реальном KNN (и много где еще) используется структура данных [k-d-tree](https://ru.wikipedia.org/wiki/K-d-%D0%B4%D0%B5%D1%80%D0%B5%D0%B2%D0%BE), которая позволяет производить поиск за log(N), а не за N, как будем делать мы. По сути это такое расширение бинарного поиска на многомерное пространство. В нашем случае это не критично, но при работе с метриками расстояния на больших данных вы можете сильно выиграть в скорости, так что советую запомнить про это.\n",
    "\n",
    "Вам нужно будет реализовать метод `compute_distances` класса `KNN` в файле `knn.py` (20 баллов).\n",
    "\n",
    "Эта функция строит массив расстояний между всеми векторами в тестовом наборе и в тренировочном наборе.  \n",
    "В результате она должна построить массив размера `(num_test, num_train)`, где координата `[i][j]` соотвествует расстоянию между i-м вектором в test (`test[i]`) и j-м вектором в train (`train[j]`).\n",
    "\n",
    "**Обратите внимание 1:** Для простоты реализации мы будем использовать в качестве расстояния меру L1 (ее еще называют [Manhattan distance](https://ru.wikipedia.org/wiki/%D0%A0%D0%B0%D1%81%D1%81%D1%82%D0%BE%D1%8F%D0%BD%D0%B8%D0%B5_%D0%B3%D0%BE%D1%80%D0%BE%D0%B4%D1%81%D0%BA%D0%B8%D1%85_%D0%BA%D0%B2%D0%B0%D1%80%D1%82%D0%B0%D0%BB%D0%BE%D0%B2)), а в качестве ядра -- triangle.\n",
    "\n",
    "$d_{1}(\\mathbf {p} ,\\mathbf {q} )=\\|\\mathbf {p} -\\mathbf {q} \\|_{1}=\\sum _{i=1}^{n}|p_{i}-q_{i}|$\n",
    "\n",
    "**Обратите внимание 2:** Посмотрите на комментарии к функциям и методам в `metrics.py` и `knn.py`. Они описывают тип принимаемых аргументов и тип возврата. Написание таких комментариев и работа по ним - это важный элемент разработки кода, так что обращайте на них внимание."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полсе написания функции, метода и вообще какого-то кода стоит провести тест и проверить, что он работает правильно.\n",
    "\n",
    "Ниже приведен пример assert'ов, чтобы можно было проверить правильность реализации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute_distances\n",
    "dists = knn_classifier.compute_distances(binary_test_X)\n",
    "assert np.isclose(dists[0, 100], np.sum(np.abs(binary_test_X[0] - binary_train_X[100])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим скорость работы реализованных методов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit knn_classifier.compute_distances(binary_test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем метод для предсказания меток класса. Обратите внимание на ожидаемый формат возврата в методе `.predict()`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: predict_labels_binary in knn.py (10 баллов)\n",
    "prediction = knn_classifier.predict(binary_test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.2 Метрика (15 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь нужно реализовать несколько метрик для бинарной классификации.\n",
    "Не забудьте подумать (и никогда не забывайте) о численной нестабильности (деление на 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: binary_classification_metrics in metrics.py (10 баллов)\n",
    "binary_classification_metrics(prediction, binary_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все ли хорошо с моделью? Можно проверить свою реализацию с функциями из библиотеки `sklearn`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgflip.com/406fu9.jpg\" width=\"800\" height=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сравниваем со sklearn (5 баллов)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор оптимального k (15 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы подрбрать оптимальное значение параметра k можно сделать следующее: задать область допустимых значений k, например, `[1, 3, 5, 10]`. Дальше для каждого k обучить модель на тренировочных данных, сделать предсказания на тестовых и посчитать какую-нибудь метрику (а лучше несколько и сравнить).\n",
    "\n",
    "В конце нужно посмотреть на зависимость метрики на train'е и test'е от k и выбрать подходящее значение.\n",
    "\n",
    "Реализуйте функцию `choose_best_k` прямо в ноутбуке. (10 баллов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_k(X_train, y_train, X_test, y_test, params, metric):\n",
    "    \"\"\"\n",
    "    Choose the best k for KKNClassifier\n",
    "    Arguments:\n",
    "    X_train, np array (num_train_samples, num_features) - train data\n",
    "    y_train, np array (num_train_samples) - train labels\n",
    "    X_test, np array (num_test_samples, num_features) - test data\n",
    "    y_test, np array (num_test_samples) - test labels\n",
    "    params, list of hyperparameters for KNN, here it is list of k values\n",
    "    metric, function for metric calculation\n",
    "    Returns:\n",
    "    train_metrics the list of metric values on train data set for each k in params\n",
    "    test_metrics the list of metric values on test data set for each k in params\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    YOUR CODE IS HERE\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = [1, 2, 4, 5, 8, 10, 30]\n",
    "train_metrics, test_metrics = find_best_k(binary_train_X, binary_train_y, binary_test_X, binary_test_y, params, accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(params, train_metrics, label=\"train\")\n",
    "plt.plot(params, test_metrics, label=\"test\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"K in KNN\")\n",
    "plt.ylabel(\"YOUR METRIC\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Опишите результат. Какое k оптимальное и почему? (5 баллов)**\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На самом деле, это не самый лучший способ подбирать гиперпараметры, но способы получше мы рассмотрим в следующий раз, а пока что выберите оптимальное значение k, сделайте предсказания и посмотрите, насколько хорошо ваша модель предсказывает каждый из классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# обучение и предсказание с оптимальным k\n",
    "\n",
    "# метрики классификации\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очень полезная практика - смотреть на несколько числовых метрик модели и на визуализации. \n",
    "\n",
    "Так при работе с классификацией очень полезно посмотреть на Confusion Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(binary_test_y, predictions)\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cf_matrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Многоклассоввая классификация (5 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь нужно научиться предсказывать все 10 классов. Для этого в начале напишем соответствующий метод у нашего классификатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: predict_labels_multiclass in knn.py\n",
    "knn_classifier = KNNClassifier(k=1)\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "predictions = knn_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осталось реализовать метрику качества для многоклассовой классификации, для этого реализуйте функцию `multiclass_accuracy` в `metrics.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: multiclass_accuracy in metrics.py (5 баллов)\n",
    "multiclass_accuracy(predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6. K-fold cross validation (20 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Снова выберите оптимальное значение k. На этот раз давайте сделаем это с использованием KFoldCrossValidation. Реализуйте функцию `n_fold_cv`, которая будет разделять ваши данные на `n` частей, после чего последовательно тренировать модели на всех частях кроме одной.\n",
    "\n",
    "В результате такого подхода у вас для каждого параметра k алгоритма k-ближайших соседей получится по n моделей. Для каждого значения параметра k отобразите боксплот с распределением метрики `multiclass_accuracy` по каждому из фолдов. Выберите лучшую модель. (20 баллов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2. KNN на датасете diabetes\n",
    "\n",
    "**50 баллов**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем применить KNN к задаче регрессии. Будем работать с [данными](https://scikit-learn.org/stable/datasets/toy_dataset.html#diabetes-dataset) о диабете. В этом задании будем использовать класс `KNeighborsRegressor` из библиотеки `sklearn`. Загрузим необходимые библиотеки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_diabetes(as_frame=True, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. EDA (10 обязательных баллов + 10 доп. баллов за Pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделайте EDA, предобработайте данные так, как считаете нужным и **прокомментируйте выбор стратегии**.\n",
    "\n",
    "Вопрос: нужна ли в данном случае стандартизация и почему? \n",
    "\n",
    "Не забудте, что если вы стандартизуете данные, то нужно считать среднее и сдандартное отклонение на тренировочной части и с помощью них трансформировать и train, и test, и validate (**если не поняли это предложение, то обязательно разберитесь**).\n",
    "\n",
    "Разбейте ваши данные на train и test.\n",
    "\n",
    "**Дополнительно**:\n",
    "Попробуйте разобраться с [`Pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html), чтобы можно было создать класс, который сразу проводит стандартизацию и обучает модель (или делает предсказание). Пайплайны очень удобны, когда нужно применять различные методы предобработки данных (в том числе и к разным столбцам), а также они позволяют правильно интегрировать предобработку данных в различные классы для поиска наилучших гиперпараметров модели (например, `GridSearchCV`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш ход"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ваши выводы из EDA:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Регрессионная модель (5 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создайте модель `KNeighborsRegressor`, обучите ее на треноровочных данных и сделайте предсказания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Метрики регресии (5 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте метрики $R^2$, MSE и  MAE в `metrics.py`. Примените их для оценки качества полученной модели.\n",
    "Все ли хорошо?\n",
    "\n",
    "Напомню, что:\n",
    "\n",
    "$R^2 = 1 - \\frac{\\sum_i^n{(y_i - \\hat{y_i})^2}}{\\sum_i^n{(y_i - \\overline{y})^2}}$\n",
    "\n",
    "$MSE = \\frac{1}{n}\\sum_i^n{(y_i - \\hat{y_i})^2}$\n",
    "\n",
    "$MAE = \\frac{1}{n}\\sum_i^n{|y_i - \\hat{y_i}|}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: r_squared, mse, mae in metrics.py\n",
    "from metrics import r_squared, mse, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверьте ваши метрики на модельных примерах и на предсказаниях модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Подбор оптимальных гиперпараметров (20 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы почти дошли до конца. Теперь давайте использовать метрику MSE (можно использовать встроенную в sklearn) и с ее помощью подберем гиперпараметры для нашей модели.\n",
    "\n",
    "Подберите оптимальные гиперпараметры для вашей модели. Просмотрите возможные варианты для метрик расстояния и ядра, а также подберите значение k. Для этого используйте класс GridSearchCV из sklearn. Обратите внимание, что GridSearchCV испольузет k-fold кросс-валидацию (параметр `cv`), а для выбора метрики используется параметр `scoring`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какое получились оптимальные параметры? Для лчшей модели проведите обучение на всем тренировочном датасете и сделайте предсказания на тесте.**\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# модель и метрики с оптимальным k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Therapy time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите здесь ваши впечатления о задании: было ли интересно, было ли слишком легко или наоборот сложно и тд. Также сюда можно написать свои идеи по улучшению заданий, а также предложить данные, на основе которых вы бы хотели построить следующие дз. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ваши мысли:**\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemvae",
   "language": "python",
   "name": "chemvae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
